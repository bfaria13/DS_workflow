# DATA SCIENCE WORKFLOW

**Bruna F Faria** - PhD in Computing, Data Science and Engineering

Mentora de Ciência de Dados na Escola Online Mentorama.

***

##### Este projeto tem como objetivo demonstrar toda a sequência de trabalho do cientista de dados bem como suas principais ferramentas de trabalho.



O trabalho do cientista de dados pode ser dividido nas seguintes etapas:

1) Definição do problema
2) Aquisição de dados
3) Preparação dos dados
4) Analise exploratória dos dados
5) Criação de modelos de ML/DL
6) Apresentação dos resultados
7) Deploy do modelo

________________

**1) Definição do problema:**

Essa é a etapa em que o cientista recebe ou cria a proposta do trabalho, ou seja, define os objetivos do trabalho, os objetos de entrega (análises, modelos, etc). Lembrando que é essencial que o problema fique claro para o correto desenvolvimento do trabalho.

O conteúdo do arquivo _E1_Introducao.pdf_ traz uma boa discussão sobre os principais pontos dentro do universo da Ciência de Dados bem como os tipos de problemas resolvidos por um cientista de dados.



**2) Aquisição dos dados:**

Após entender a ideia e objeto de entrega do trabalho, o cientista precisa coletar todos os dados para iniciar o trabalho. Os dados podem vim de diferentes fonte, por exemplo:

- Interno
- Web servers
- Bancos de dados
- Repositórios online

No notebook _E2_AquisicaoDados.ipynb_ será demonstrado várias ferramentas importantes para se trabalhar com diferentes tipos e fontes de dados. Incluindo um tutorial de _web scrapping_.



**3) Preparação dos dados:** 

Os dados coletados na etapa anterior precisam passar por um pré-processamento para enfim seguirem para a etapa da Análise exploratória.

No notebook _E3_PreparacaoDados.ipynb_ serão trabalhados os seguintes pontos:

* Visualização de dados numéricos e categóricos
* Tratamento e Limpeza dos dados:
  * valores faltantes
  * normalização e padronização 
  * categorização (Encoders)
  * detecção de outliers

* Feature engineering



**4) Análise exploratória de dados (EAD):** (Será adicionada em breve)

A ideia nessa parte do curso é demonstrar os principais pontos a serem trabalhados na EAD.

No notebook _E4_EAD.ipynb_ serão apresentadas as análises básicas dos dados, análises estatísticas - testes de hipóteses e interpretação dos gráficos, seleção de variáveis alvo e a geração de relatório de análises.



**5) Criação de modelos de ML/DL:** (Será adicionada em breve)

Baseado nos resultados da EDA, agora já temos nossa(s) variável(is) alvo bem definidas e o trabalho bem delineado. Então nesse ponto estaremos testando alguns algoritmos afim de criar bons modelos.

No notebook _E5_Modelos.ipynb_ trabalharemos modelos de regressão e classificação bem como alguns modelos não supervisionados. Além disso, as diferentes métricas aplicadas a cada tipo de modelo e sua interpretação.



**6) Apresentação dos resultados: **(Será adicionada em breve)

Após a conclusão do trabalho metodológico é preciso criar um bom relatório/apresentação que comunique os principais achados de forma confiante e adequada para todo tipo de publico. A comunicação dos resultados ainda é um desafio para as carreiras ligadas a computação, porém como cientistas devemos ser abeis ao ponto de passar todo conhecimento de forma que leigos entendam nosso trabalho e a importância dos nossos achados.



**7) Deploy de modelos: **(Será adicionada em breve)

Por fim, o modelo criado pode ser colocado em produção, ou seja, pode-se criar uma aplicação para testar o modelo em larga escala.

Aqui será apresentado de maneira simples como podemos criar uma aplicação local e hospedada para testar nosso modelo - notebook _E7_Deploy.ipynb_.

Como essa etapa concluímos nosso workflow do trabalho do cientista de dados.

-------------------------





